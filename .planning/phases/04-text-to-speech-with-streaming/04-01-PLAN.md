---
phase: 04-text-to-speech-with-streaming
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - requirements.txt
  - src/tts/__init__.py
  - src/tts/config.py
  - src/tts/client.py
  - src/config.py
  - .env.example
  - tests/test_tts_client.py
autonomous: true
requirements: [TTS-01, TTS-02, TTS-03]

must_haves:
  truths:
    - "TTS client accepts text and yields audio chunks (bytes)"
    - "TTS client supports both complete text and streaming text input"
    - "CPU/dev fallback works without GPU (kokoro or pyttsx3)"
    - "TTS output is raw PCM audio (resampling handled by caller)"
  artifacts:
    - path: "src/tts/client.py"
      provides: "TTS client with streaming audio generation"
      exports: ["TTSClient"]
      min_lines: 60
    - path: "src/tts/config.py"
      provides: "TTS configuration"
      exports: ["TTSConfig"]
      min_lines: 15
    - path: "tests/test_tts_client.py"
      provides: "Unit tests for TTS client"
      min_lines: 40
  key_links:
    - from: "src/tts/client.py"
      to: "kokoro (pip package)"
      via: "CPU/dev TTS engine"
      pattern: "kokoro"
    - from: "src/tts/config.py"
      to: "src/config.py"
      via: "TTS configuration settings"
      pattern: "settings"
---

<objective>
Create a TTS client module that accepts text and yields streaming audio chunks.

Purpose: Provide a TTS engine that generates natural-sounding speech from LLM response text. Uses kokoro for CPU/dev environments and will support CSM for GPU/production. The client streams audio chunks as they generate — does not wait for full synthesis.

Output: TTSClient class with synthesize() async generator that yields PCM audio chunks, configurable via environment variables.
</objective>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install kokoro TTS and add TTS config</name>
  <files>requirements.txt, src/tts/config.py, src/config.py, .env.example</files>
  <action>
Add kokoro to requirements.txt:

```
# Text-to-Speech (TTS) - kokoro for CPU/dev, CSM for GPU/production
kokoro>=0.9.0
soundfile>=0.13.0
```

Install:
```bash
pip install kokoro>=0.9.0 soundfile>=0.13.0
```

Create `src/tts/config.py` with TTS configuration:

```python
"""TTS configuration."""

from dataclasses import dataclass

@dataclass
class TTSConfig:
    engine: str = "kokoro"        # "kokoro" (CPU/dev) or "csm" (GPU/prod)
    voice: str = "af_heart"       # Kokoro voice ID
    speed: float = 1.0            # Speech speed multiplier
    sample_rate: int = 24000      # Kokoro native output sample rate
    chunk_size: int = 4800        # Samples per chunk (200ms at 24kHz)
```

Update `src/config.py` to add TTS settings:

```python
# TTS Configuration
tts_engine: str = "kokoro"
tts_voice: str = "af_heart"
tts_speed: float = 1.0
```

Update `.env.example` with TTS settings.
  </action>
  <verify>
```bash
python -c "from kokoro import KPipeline; print('kokoro imported')"
python -c "from src.tts.config import TTSConfig; print('TTSConfig imported')"
```
  </verify>
  <done>
kokoro installed, TTS config module created, settings updated.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create TTSClient with streaming audio generation</name>
  <files>src/tts/__init__.py, src/tts/client.py</files>
  <action>
Create `src/tts/client.py`:

The TTSClient wraps kokoro's KPipeline and provides:
- `synthesize(text: str)` — async generator yielding PCM int16 numpy chunks
- `synthesize_streaming(text_stream: AsyncGenerator)` — accepts streaming text, yields audio as sentences complete
- Sentence-level chunking: kokoro generates per-sentence, we yield each sentence's audio immediately
- Output: raw PCM numpy arrays at kokoro's native sample rate (24kHz) — caller handles resampling

Key design decisions:
- Kokoro runs on CPU (no GPU required for dev)
- KPipeline is loaded once (shared), synthesis is stateless per-call
- Use asyncio.to_thread() for blocking kokoro calls
- Stream at sentence boundaries for natural prosody

Create `src/tts/__init__.py`:
```python
from .client import TTSClient
__all__ = ["TTSClient"]
```
  </action>
  <verify>
```bash
python -c "from src.tts import TTSClient; print('TTSClient imported')"
```
  </verify>
  <done>
TTSClient class exists with synthesize() and synthesize_streaming() methods.
  </done>
</task>

<task type="auto">
  <name>Task 3: Create unit tests for TTS client</name>
  <files>tests/test_tts_client.py</files>
  <action>
Create `tests/test_tts_client.py`:

Tests:
- TTSClient initialization with default config
- TTSClient initialization with custom config
- synthesize() yields numpy int16 audio chunks
- synthesize_streaming() accepts text iterator and yields audio
- Audio output has correct dtype (int16) and is non-empty

Uses mocking to avoid loading the actual kokoro model in unit tests.
  </action>
  <verify>
```bash
pytest tests/test_tts_client.py -v
```
  </verify>
  <done>
Unit tests pass, verifying TTSClient API contract.
  </done>
</task>

</tasks>

<verification>
1. **Dependencies installed:** `pip list | grep kokoro`
2. **Config works:** `python -c "from src.tts.config import TTSConfig; print(TTSConfig())"`
3. **Module imports:** `python -c "from src.tts import TTSClient"`
4. **Tests pass:** `pytest tests/test_tts_client.py -v`
</verification>

<success_criteria>
- kokoro package installed
- TTSClient class with async streaming synthesis
- Configurable via TTSConfig (engine, voice, speed)
- Unit tests pass with mocked TTS engine
- Ready for audio pipeline integration in Plan 02
</success_criteria>

<output>
After completion, create `.planning/phases/04-text-to-speech-with-streaming/04-01-SUMMARY.md` following the summary template.
</output>
