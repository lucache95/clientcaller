---
phase: 04-text-to-speech-with-streaming
plan: 03
type: execute
wave: 3
depends_on: [04-01, 04-02]
files_modified:
  - src/twilio/handlers.py
  - tests/test_e2e_tts.md
autonomous: true
requirements: [TTS-01, TTS-02, TTS-03]

must_haves:
  truths:
    - "Complete conversation loop: user speaks → STT → LLM → TTS → user hears AI"
    - "LLM response tokens stream into TTS as they generate"
    - "TTS audio streams to caller via AudioStreamer as it generates"
    - "Per-call TTS cleanup in handle_stop()"
  artifacts:
    - path: "src/twilio/handlers.py"
      provides: "Full conversation pipeline with TTS"
    - path: "tests/test_e2e_tts.md"
      provides: "E2E testing checklist for TTS integration"
  key_links:
    - from: "src/twilio/handlers.py"
      to: "src/tts/stream.py"
      via: "TTSStream for text-to-audio pipeline"
      pattern: "TTSStream"
    - from: "src/twilio/handlers.py"
      to: "src/audio/buffers.py"
      via: "AudioStreamer.queue_audio() for sending to Twilio"
      pattern: "queue_audio"
---

<objective>
Wire TTS into the Twilio handler pipeline to complete the full conversation loop.

Purpose: Replace the TODO in handle_media() with actual TTS synthesis and audio playback. When user finishes speaking, the AI response streams through TTS and the caller hears the AI speak.

Output: Complete conversation flow — user speaks → AI transcribes → AI thinks → AI speaks back.
</objective>

<context>
@src/twilio/handlers.py
@src/tts/stream.py
@src/audio/buffers.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Integrate TTS into handle_media pipeline</name>
  <files>src/twilio/handlers.py</files>
  <action>
Update handle_media() to:
1. After LLM generates response text, pass it to TTSStream.generate()
2. For each audio payload from TTSStream, queue it via AudioStreamer.queue_audio()
3. Add TTSStream to ConnectionManager (shared TTS client, per-call stream)
4. Add TTS cleanup in handle_stop()

The key change: replace the `# TODO Phase 4` comment with actual TTS pipeline:

```python
# Stream LLM response through TTS to caller
tts_stream = manager.get_tts_stream()
streamer = manager.get_streamer(call_sid)
if streamer:
    async for audio_payload in tts_stream.generate(response_text):
        await streamer.queue_audio(audio_payload)
```

Also update ConnectionManager:
- Add get_tts_stream() method (shared, stateless)
- Import TTSStream
  </action>
  <verify>
```bash
python -c "from src.twilio.handlers import manager; print('handlers import OK')"
```
  </verify>
  <done>
Full conversation loop wired: user speaks → STT → LLM → TTS → audio to caller.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create E2E testing checklist</name>
  <files>tests/test_e2e_tts.md</files>
  <action>
Create E2E testing checklist covering:
1. Call system, speak, hear AI response
2. Multi-turn conversation (AI remembers context)
3. Long response handling (no audio cutoff)
4. Silence/empty response handling
5. Latency measurement (target: <500ms end-to-end)
  </action>
  <verify>
File exists and covers key test scenarios.
  </verify>
  <done>
E2E testing checklist created for manual telephony verification.
  </done>
</task>

</tasks>

<verification>
1. **Handler imports work:** `python -c "from src.twilio.handlers import manager"`
2. **Full test suite passes:** `pytest tests/ -v`
3. **E2E checklist:** `tests/test_e2e_tts.md` exists
</verification>

<success_criteria>
- Complete conversation loop: speak → hear AI response
- LLM tokens stream through TTS without waiting for full response
- Audio plays back to caller via AudioStreamer
- All existing tests still pass
- E2E testing checklist for manual verification
</success_criteria>

<output>
After completion, create `.planning/phases/04-text-to-speech-with-streaming/04-03-SUMMARY.md` following the summary template.
</output>
