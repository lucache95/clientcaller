---
phase: 01-telephony-foundation-audio-pipeline
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - requirements.txt
  - .env.example
  - src/main.py
  - src/config.py
  - src/twilio/models.py
  - src/twilio/handlers.py
  - src/audio/conversion.py
  - src/audio/resampling.py
autonomous: true
requirements:
  - TEL-01
  - TEL-03

must_haves:
  truths:
    - "WebSocket server accepts connections from Twilio"
    - "Server receives and parses Twilio Media Streams messages"
    - "Audio can be converted between mu-law and PCM formats"
    - "Audio can be resampled between 8kHz and 16kHz"
  artifacts:
    - path: "src/main.py"
      provides: "FastAPI application with WebSocket endpoint"
      min_lines: 40
    - path: "src/twilio/handlers.py"
      provides: "Message handlers for connected, start, media, stop events"
      min_lines: 60
    - path: "src/audio/conversion.py"
      provides: "Mu-law ↔ PCM conversion functions"
      exports: ["mulaw_to_pcm", "pcm_to_mulaw"]
    - path: "src/audio/resampling.py"
      provides: "8kHz ↔ 16kHz resampling functions"
      exports: ["resample_8k_to_16k", "resample_16k_to_8k"]
  key_links:
    - from: "src/main.py"
      to: "src/twilio/handlers.py"
      via: "async for message pattern in WebSocket handler"
      pattern: "async for.*message.*websocket"
    - from: "src/twilio/handlers.py"
      to: "src/audio/conversion.py"
      via: "import and call mulaw_to_pcm on media payload"
      pattern: "from.*audio.*conversion.*import|mulaw_to_pcm"
---

<objective>
Establish the foundational infrastructure for real-time telephony by creating a FastAPI WebSocket server that handles Twilio Media Streams connections and implements audio format conversion pipeline.

Purpose: Build the core components needed for bidirectional audio streaming before adding complexity of state management and call orchestration.
Output: Working WebSocket endpoint that can receive Twilio connections, parse messages, and convert audio between telephony and ML model formats.
</objective>

<execution_context>
@/Users/lucassenechal/.claude/get-shit-done/workflows/execute-plan.md
@/Users/lucassenechal/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/REQUIREMENTS.md
@.planning/phases/01-telephony-foundation-audio-pipeline/01-RESEARCH.md
@.planning/research/STACK.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Initialize project structure and dependencies</name>
  <files>
    requirements.txt
    .env.example
    src/__init__.py
    src/config.py
    src/twilio/__init__.py
    src/audio/__init__.py
  </files>
  <action>
Create Python project structure following research-recommended layout:

```
src/
├── main.py (FastAPI app)
├── config.py (configuration management)
├── twilio/
│   ├── __init__.py
│   ├── models.py (Pydantic models)
│   └── handlers.py (message handlers)
└── audio/
    ├── __init__.py
    ├── conversion.py (mu-law ↔ PCM)
    └── resampling.py (8kHz ↔ 16kHz)
```

Create requirements.txt with exact versions from research:
```
fastapi[standard]>=0.115.0
uvicorn[standard]>=0.40.0
twilio>=9.10.1
pydub>=0.25.1
soundfile>=0.12.1
numpy>=1.26.0
librosa>=0.11.0
pydantic>=2.10.0
python-dotenv>=1.0.0
websockets>=16.0
pytest>=8.0.0
pytest-asyncio>=0.25.0
httpx>=0.27.0
```

Create .env.example with:
```
TWILIO_ACCOUNT_SID=your_account_sid_here
TWILIO_AUTH_TOKEN=your_auth_token_here
TWILIO_PHONE_NUMBER=+1234567890
SERVER_HOST=0.0.0.0
SERVER_PORT=8000
```

Create src/config.py using pydantic for type-safe configuration:
```python
from pydantic_settings import BaseSettings
from pydantic import Field

class Settings(BaseSettings):
    twilio_account_sid: str = Field(..., env="TWILIO_ACCOUNT_SID")
    twilio_auth_token: str = Field(..., env="TWILIO_AUTH_TOKEN")
    twilio_phone_number: str = Field(..., env="TWILIO_PHONE_NUMBER")
    server_host: str = Field(default="0.0.0.0", env="SERVER_HOST")
    server_port: int = Field(default=8000, env="SERVER_PORT")

    class Config:
        env_file = ".env"
        case_sensitive = False

settings = Settings()
```

Note: FFmpeg is required system dependency for pydub. Add comment in requirements.txt:
```
# System dependencies (install separately):
# macOS: brew install ffmpeg
# Linux: sudo apt-get install ffmpeg
```
  </action>
  <verify>
Run `pip install -r requirements.txt` successfully.
Run `python -c "from src.config import settings; print('Config loaded')"` (create empty .env first).
Verify all src/ subdirectories have __init__.py files.
  </verify>
  <done>
requirements.txt exists with correct dependencies.
Project structure matches research-recommended layout.
Configuration module loads without errors.
All imports work without ImportError.
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement FastAPI WebSocket endpoint with Twilio message handling</name>
  <files>
    src/main.py
    src/twilio/models.py
    src/twilio/handlers.py
  </files>
  <action>
Create Pydantic models for Twilio message validation in src/twilio/models.py:

```python
from pydantic import BaseModel, Field
from typing import Optional, Literal

class MediaFormat(BaseModel):
    encoding: str  # "audio/x-mulaw"
    sampleRate: int  # 8000
    channels: int  # 1

class StartMessage(BaseModel):
    streamSid: str
    callSid: str
    tracks: list[str]
    mediaFormat: MediaFormat

class MediaPayload(BaseModel):
    payload: str  # base64-encoded audio

class TwilioMessage(BaseModel):
    event: Literal["connected", "start", "media", "stop", "mark", "dtmf"]
    streamSid: Optional[str] = None
    start: Optional[StartMessage] = None
    media: Optional[MediaPayload] = None
    sequenceNumber: Optional[int] = None
```

Create message handlers in src/twilio/handlers.py following Pattern 1 from research:

```python
import json
import base64
import logging
from typing import Dict
from fastapi import WebSocket

logger = logging.getLogger(__name__)

class ConnectionManager:
    def __init__(self):
        self.active_connections: Dict[str, WebSocket] = {}

    async def connect(self, call_sid: str, websocket: WebSocket):
        await websocket.accept()
        self.active_connections[call_sid] = websocket
        logger.info(f"Connection accepted for call: {call_sid}")

    def disconnect(self, call_sid: str):
        self.active_connections.pop(call_sid, None)
        logger.info(f"Connection removed for call: {call_sid}")

    def get(self, call_sid: str) -> WebSocket:
        return self.active_connections.get(call_sid)

manager = ConnectionManager()

async def handle_connected(websocket: WebSocket, data: dict):
    """Handle 'connected' event from Twilio"""
    logger.info("WebSocket connected to Twilio")

async def handle_start(websocket: WebSocket, data: dict):
    """Handle 'start' event - extract call metadata"""
    start_data = data.get("start", {})
    call_sid = start_data.get("callSid")
    stream_sid = start_data.get("streamSid")
    media_format = start_data.get("mediaFormat", {})

    logger.info(f"Stream started: {stream_sid}, Call: {call_sid}")
    logger.info(f"Media format: {media_format}")

    # Store connection
    await manager.connect(call_sid, websocket)

async def handle_media(websocket: WebSocket, data: dict):
    """Handle 'media' event - receive audio from Twilio"""
    media_data = data.get("media", {})
    payload = media_data.get("payload")

    if not payload:
        logger.warning("Received media event with no payload")
        return

    # Decode base64 audio
    audio_bytes = base64.b64decode(payload)

    # TODO: Process audio (convert mu-law → PCM, send to STT)
    # For now, just log receipt
    logger.debug(f"Received audio chunk: {len(audio_bytes)} bytes")

    # Echo audio back for testing (simple passthrough)
    response = {
        "event": "media",
        "streamSid": data.get("streamSid"),
        "media": {
            "payload": payload  # Echo back same audio
        }
    }
    await websocket.send_text(json.dumps(response))

async def handle_stop(websocket: WebSocket, data: dict):
    """Handle 'stop' event - stream ending"""
    stop_data = data.get("stop", {})
    call_sid = stop_data.get("callSid")

    logger.info(f"Stream stopped: {call_sid}")

    if call_sid:
        manager.disconnect(call_sid)

# Message router
MESSAGE_HANDLERS = {
    "connected": handle_connected,
    "start": handle_start,
    "media": handle_media,
    "stop": handle_stop,
    # mark and dtmf events are optional, can be added later
}
```

Create FastAPI application in src/main.py:

```python
import json
import logging
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from src.config import settings
from src.twilio.handlers import MESSAGE_HANDLERS, manager

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

app = FastAPI(title="Client Caller - Telephony Server")

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "active_connections": len(manager.active_connections)
    }

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    """
    WebSocket endpoint for Twilio Media Streams.

    Handles bidirectional audio streaming with message-based protocol.
    """
    await websocket.accept()
    call_sid = None

    try:
        async for message in websocket.iter_text():
            try:
                data = json.loads(message)
                event = data.get("event")

                if not event:
                    logger.warning(f"Received message without event type: {message[:100]}")
                    continue

                # Track call_sid from start message for cleanup
                if event == "start":
                    call_sid = data.get("start", {}).get("callSid")

                # Route to appropriate handler
                handler = MESSAGE_HANDLERS.get(event)
                if handler:
                    await handler(websocket, data)
                else:
                    logger.warning(f"No handler for event type: {event}")

            except json.JSONDecodeError as e:
                logger.error(f"Failed to parse JSON message: {e}")
            except Exception as e:
                logger.error(f"Error handling message: {e}", exc_info=True)

    except WebSocketDisconnect:
        logger.info(f"WebSocket disconnected: {call_sid}")
    except Exception as e:
        logger.error(f"WebSocket error: {e}", exc_info=True)
    finally:
        # Cleanup on disconnect
        if call_sid:
            manager.disconnect(call_sid)

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "src.main:app",
        host=settings.server_host,
        port=settings.server_port,
        reload=True,
        log_level="info"
    )
```

Use pattern from research: accept WebSocket immediately, handle all message types (connected, start, media, stop), track active connections by call_sid, decode base64 audio payloads, echo audio back for initial testing.
  </action>
  <verify>
Create empty .env file with dummy credentials.
Run `python -m src.main` and verify server starts without errors.
Check `/health` endpoint returns 200 with `curl http://localhost:8000/health`.
Verify logs show "Application startup complete" or similar.
  </verify>
  <done>
FastAPI server starts successfully on port 8000.
WebSocket endpoint exists at /ws.
Health endpoint returns status with active connection count.
Message handlers exist for connected, start, media, stop events.
ConnectionManager tracks active calls by call_sid.
  </done>
</task>

<task type="auto">
  <name>Task 3: Implement audio format conversion and resampling modules</name>
  <files>
    src/audio/conversion.py
    src/audio/resampling.py
    tests/test_audio_conversion.py
  </files>
  <action>
Implement mu-law ↔ PCM conversion in src/audio/conversion.py following Pattern 2 from research:

```python
"""
Audio format conversion: mu-law ↔ PCM

Twilio uses 8-bit mu-law encoding (telephony standard).
ML models expect 16-bit PCM.

Note: Using pydub instead of deprecated audioop module (removed Python 3.13).
"""
import numpy as np
import io
from pydub import AudioSegment
import logging

logger = logging.getLogger(__name__)

def mulaw_to_pcm(mulaw_bytes: bytes, sample_rate: int = 8000) -> np.ndarray:
    """
    Convert mu-law encoded bytes to PCM numpy array.

    Args:
        mulaw_bytes: Raw mu-law audio bytes from Twilio
        sample_rate: Sample rate (Twilio uses 8000 Hz)

    Returns:
        numpy array of int16 PCM samples
    """
    try:
        # Create AudioSegment from mu-law bytes
        audio = AudioSegment.from_file(
            io.BytesIO(mulaw_bytes),
            format="mulaw",
            frame_rate=sample_rate,
            channels=1,
            sample_width=1  # mu-law is 8-bit
        )

        # Convert to 16-bit PCM
        pcm_audio = audio.set_sample_width(2)  # 2 bytes = 16-bit

        # Convert to numpy array
        samples = np.array(pcm_audio.get_array_of_samples(), dtype=np.int16)

        logger.debug(f"Converted mu-law to PCM: {len(samples)} samples")
        return samples

    except Exception as e:
        logger.error(f"Error converting mu-law to PCM: {e}")
        raise

def pcm_to_mulaw(pcm_samples: np.ndarray, sample_rate: int = 8000) -> bytes:
    """
    Convert PCM numpy array to mu-law encoded bytes.

    Args:
        pcm_samples: numpy array of int16 PCM samples
        sample_rate: Sample rate (Twilio expects 8000 Hz)

    Returns:
        mu-law encoded bytes (base64 encode before sending to Twilio)
    """
    try:
        # Ensure correct dtype
        if pcm_samples.dtype != np.int16:
            pcm_samples = pcm_samples.astype(np.int16)

        # Create AudioSegment from numpy array
        audio = AudioSegment(
            pcm_samples.tobytes(),
            frame_rate=sample_rate,
            sample_width=2,  # 16-bit PCM
            channels=1
        )

        # Export as mu-law
        buffer = io.BytesIO()
        audio.export(buffer, format="mulaw", codec="pcm_mulaw")
        mulaw_bytes = buffer.getvalue()

        logger.debug(f"Converted PCM to mu-law: {len(mulaw_bytes)} bytes")
        return mulaw_bytes

    except Exception as e:
        logger.error(f"Error converting PCM to mu-law: {e}")
        raise

def twilio_to_model_format(mulaw_payload: str) -> np.ndarray:
    """
    Complete conversion from Twilio audio to ML model format.

    Pipeline: base64 → mu-law bytes → PCM 8kHz → (caller resamples to 16kHz)

    Args:
        mulaw_payload: Base64-encoded mu-law audio from Twilio

    Returns:
        numpy array of 16-bit PCM samples at 8kHz (ready for resampling)
    """
    import base64

    # Decode base64
    mulaw_bytes = base64.b64decode(mulaw_payload)

    # Convert mu-law → PCM
    pcm_8k = mulaw_to_pcm(mulaw_bytes, sample_rate=8000)

    return pcm_8k

def model_to_twilio_format(pcm_8k: np.ndarray) -> str:
    """
    Complete conversion from ML model output to Twilio format.

    Pipeline: PCM 8kHz → mu-law → base64

    Args:
        pcm_8k: numpy array of 16-bit PCM samples at 8kHz (already resampled)

    Returns:
        Base64-encoded mu-law audio for Twilio
    """
    import base64

    # Convert PCM → mu-law
    mulaw_bytes = pcm_to_mulaw(pcm_8k, sample_rate=8000)

    # Encode base64
    mulaw_payload = base64.b64encode(mulaw_bytes).decode('utf-8')

    return mulaw_payload
```

Implement resampling in src/audio/resampling.py following Pattern 3 from research:

```python
"""
Audio resampling: 8kHz ↔ 16kHz

Twilio streams 8kHz audio (telephony standard).
Whisper and ML models expect 16kHz+ audio.

Using librosa with kaiser_fast for speed (5x faster than default).
"""
import librosa
import numpy as np
import logging

logger = logging.getLogger(__name__)

def resample_8k_to_16k(audio_8k: np.ndarray) -> np.ndarray:
    """
    Resample audio from 8kHz to 16kHz for ML models.

    Args:
        audio_8k: numpy array of samples at 8kHz

    Returns:
        numpy array of samples at 16kHz
    """
    try:
        # Use kaiser_fast for speed (5x faster than default)
        # Trade-off: slightly lower quality but acceptable for real-time
        audio_16k = librosa.resample(
            audio_8k.astype(np.float32),
            orig_sr=8000,
            target_sr=16000,
            res_type='kaiser_fast'  # Fast resampling for real-time
        )

        result = audio_16k.astype(np.int16)
        logger.debug(f"Resampled 8kHz → 16kHz: {len(audio_8k)} → {len(result)} samples")
        return result

    except Exception as e:
        logger.error(f"Error resampling 8kHz → 16kHz: {e}")
        raise

def resample_16k_to_8k(audio_16k: np.ndarray) -> np.ndarray:
    """
    Resample audio from 16kHz to 8kHz for Twilio.

    Args:
        audio_16k: numpy array of samples at 16kHz

    Returns:
        numpy array of samples at 8kHz
    """
    try:
        audio_8k = librosa.resample(
            audio_16k.astype(np.float32),
            orig_sr=16000,
            target_sr=8000,
            res_type='kaiser_fast'
        )

        result = audio_8k.astype(np.int16)
        logger.debug(f"Resampled 16kHz → 8kHz: {len(audio_16k)} → {len(result)} samples")
        return result

    except Exception as e:
        logger.error(f"Error resampling 16kHz → 8kHz: {e}")
        raise
```

Create basic unit tests in tests/test_audio_conversion.py:

```python
import pytest
import numpy as np
from src.audio.conversion import mulaw_to_pcm, pcm_to_mulaw
from src.audio.resampling import resample_8k_to_16k, resample_16k_to_8k

def test_mulaw_roundtrip():
    """Test mu-law → PCM → mu-law preserves audio"""
    # Generate test audio (1 second sine wave at 440 Hz)
    sample_rate = 8000
    duration = 1.0
    frequency = 440
    t = np.linspace(0, duration, int(sample_rate * duration))
    original_pcm = (np.sin(2 * np.pi * frequency * t) * 32767).astype(np.int16)

    # Convert PCM → mu-law → PCM
    mulaw_bytes = pcm_to_mulaw(original_pcm, sample_rate)
    recovered_pcm = mulaw_to_pcm(mulaw_bytes, sample_rate)

    # Check similarity (mu-law is lossy, so allow some error)
    correlation = np.corrcoef(original_pcm, recovered_pcm)[0, 1]
    assert correlation > 0.95, f"Audio significantly degraded: correlation={correlation}"

def test_resampling_roundtrip():
    """Test 8kHz → 16kHz → 8kHz preserves shape"""
    # Generate 8kHz test audio
    audio_8k = np.random.randint(-32768, 32767, size=8000, dtype=np.int16)

    # Resample up and down
    audio_16k = resample_8k_to_16k(audio_8k)
    audio_8k_recovered = resample_16k_to_8k(audio_16k)

    # Check lengths approximately match (within 1%)
    assert abs(len(audio_8k_recovered) - len(audio_8k)) < len(audio_8k) * 0.01

def test_resampling_doubles_length():
    """Test that 8kHz → 16kHz approximately doubles sample count"""
    audio_8k = np.random.randint(-32768, 32767, size=8000, dtype=np.int16)
    audio_16k = resample_8k_to_16k(audio_8k)

    # Should be close to 2x (allow 5% variance for filter edge effects)
    ratio = len(audio_16k) / len(audio_8k)
    assert 1.9 < ratio < 2.1, f"Unexpected resampling ratio: {ratio}"
```

Follow research recommendations: Use pydub (not deprecated audioop), use librosa with kaiser_fast mode (5x faster), handle numpy arrays throughout pipeline, include error logging.
  </action>
  <verify>
Run `pytest tests/test_audio_conversion.py -v` and verify all tests pass.
Run `python -c "from src.audio.conversion import mulaw_to_pcm; import numpy as np; print('Conversion imports OK')"`.
Run `python -c "from src.audio.resampling import resample_8k_to_16k; import numpy as np; print('Resampling imports OK')"`.
  </verify>
  <done>
Audio conversion module exports mulaw_to_pcm and pcm_to_mulaw functions.
Resampling module exports resample_8k_to_16k and resample_16k_to_8k functions.
Unit tests pass with >95% correlation for mu-law roundtrip.
All functions use numpy arrays and handle int16 PCM format.
Functions include error handling and logging.
  </done>
</task>

</tasks>

<verification>
After all tasks complete:

1. FastAPI server starts without errors: `python -m src.main`
2. Health endpoint responds: `curl http://localhost:8000/health`
3. WebSocket endpoint exists and accepts connections (verify in logs)
4. Audio conversion tests pass: `pytest tests/ -v`
5. All imports work without errors
6. Project structure matches research recommendations

Overall phase validation:
- [ ] Server accepts WebSocket connections
- [ ] Twilio message types (connected, start, media, stop) have handlers
- [ ] Audio can be converted mu-law ↔ PCM
- [ ] Audio can be resampled 8kHz ↔ 16kHz
- [ ] Echo functionality works (audio received is sent back)
</verification>

<success_criteria>
**Measurable completion:**

1. FastAPI server runs on localhost:8000 without errors
2. `/health` endpoint returns 200 OK with connection count
3. `/ws` WebSocket endpoint accepts connections
4. Unit tests pass for audio conversion (correlation >95%)
5. Unit tests pass for audio resampling (length ratio 1.9-2.1x)
6. All Python imports succeed without ImportError
7. Message handlers exist for all Twilio event types
8. Logs show successful message parsing when server receives data

**Ready for next plan when:**
- Core infrastructure is in place
- Audio utilities are tested and working
- WebSocket server can accept connections and parse messages
- No blocking issues preventing integration work
</success_criteria>

<output>
After completion, create `.planning/phases/01-telephony-foundation-audio-pipeline/01-01-SUMMARY.md`
</output>
